{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 30 апреля 2018, 06:00   \n",
    "**Штраф за опоздание:** -2 балла после 06:00 30 апреля, -4 балла после 06:00 7 мая, -6 баллов после 06:00 14 мая, -8 баллов после 06:00 21 мая\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
	   "execution_count": null,
	   "metadata": {},
	   "outputs": [],
	   "source": [
"   import matplotlib.pyplot as plt\n",
"   import numpy as np\n",
"   import pandas as pd\n",
"   import math\n",
"   from collections import Counter\n",
"   from sklearn.datasets import load_wine\n",
"   from sklearn.ensemble import RandomForestClassifier\n",
"   from sklearn.metrics import accuracy_score, f1_score\n",
"   from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
"   from sklearn.tree import DecisionTreeClassifier\n",
"   from sklearn.grid_search import GridSearchCV\n",
"\n",
"   from functools import reduce\n",
"   from scipy.stats import randint as randint\n",
"   from scipy.stats import uniform\n",
"\n",
"   try:\n",
"       from sklearn.model_selection import GridSearchCV\n",
"       from sklearn.model_selection import RandomizedSearchCV\n",
"       from sklearn.model_selection import StratifiedKFold\n",
"   except ImportError:\n",
"       from sklearn.cross_validation import GridSearchCV\n",
"       from sklearn.cross_validation import RandomizedSearchCV\n",
"       from sklearn.cross_validation import StratifiedKFold\n",
"\n",
"   RND_SEED = 123\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
"class MyDecisionTreeClassifier:\n",
"    NON_LEAF_TYPE = 0\n",
"    LEAF_TYPE = 1\n",
"\n",
"    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=0.95, criterion='gini', max_features='sqrt'):\n",
"        self.tree = dict()\n",
"        self.min_samples_split = min_samples_split\n",
"        self.max_depth = max_depth\n",
"        self.sufficient_share = sufficient_share\n",
"        self.num_class = -1\n",
"        self.feature_importances_ = None\n",
"        if criterion == 'gini':\n",
"            self.G_function = self.__gini\n",
"            self.imperfection = self.__gini_imperfection\n",
"        elif criterion == 'entropy':\n",
"            self.G_function = self.__entropy\n",
"            self.imperfection = self.__entropy_imperfection\n",
"        elif criterion == 'misclass':\n",
"        self.G_function = self.__misclass\n",
"            self.imperfection = self.__misclass_imperfection\n",
"        else:\n",
"            print('invalid criterion name')\n",
"            raise\n",
"        if max_features == 'sqrt':\n",
"            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
"        elif max_features == 'log2':\n",
"            self.get_feature_ids = self.__get_feature_ids_log2\n",
"        elif max_features is None:\n",
"            self.get_feature_ids = self.__get_feature_ids_N\n",
"        else:\n",
"            print('invalid max_features name')\n",
"            raise\n",
"\n",
"    def __gini_imperfection(self, y):\n",
"        s = y.shape[0]\n",
"        if (s == 0):\n",
"            s += 1\n",
"        cnt = Counter(y)\n",
"        m = np.array([cnt[i] for i in list(cnt)])\n",
"        return 1 - np.sum(m**2 / s**2)\n",
"\n",
"    def __entropy_imperfection(self, y):\n",
"        s = y.shape[0]\n",
"        if (s == 0):\n",
"            s += 1\n",
"        cnt = Counter(y)\n",
"        m = np.array([cnt[i] for i in list(cnt)])\n",
"        return np.sum((m / s) * np.log2(m / s)) * (-1)\n",
"\n",
"    def __misclass_imperfection(self, y):\n",
"        if (s == 0):\n",
"            s += 1\n",
"        cnt = Counter(y)\n",
"        m = np.array([cnt[i] for i in list(cnt)])\n",
"        return 1 - np.max(m / s)\n",
"\n",
"    def __gini(self, l_c, l_s, r_c, r_s):\n",
"        r_s[r_s == 0] = 1\n",
"        l_s[l_s == 0] = 1\n",
"        l_s = l_s.astype('float')\n",
"        r_s = r_s.astype('float')\n",
"        return (1 - ((np.array((l_c / l_s) ** 2).sum(axis=1)) * ((l_s / (l_s + r_s)).T) + (np.array((r_c / r_s) ** 2).sum(axis=1)) *((r_s / (l_s + r_s)).T)).T)\n",
"\n",
"    def __entropy(self, l_c, l_s, r_c, r_s):\n",
"        l_c[l_c == 0] = 1\n",
"        l_s[l_s == 0] = 1\n",
"        r_c[r_c == 0] = 1\n",
"        r_s[r_s == 0] = 1\n",
"        return ((-np.array((l_c / l_s) * (np.log(l_c) - np.log(l_s)))).sum(axis=1)) - (np.array(((r_c / r_s) * (np.log(r_c) - np.log(r_s)))).sum(axis=1))\n",
"\n",
"    def __misclass(self, l_c, l_s, r_c, r_s):\n",
"        l_s[l_s == 0] = 1\n",
"        r_s[r_s == 0] = 1\n",
"        return 1 - (l_c / l_s + r_c / r_s).max(axis=1)\n",
"\n",
"    def __get_feature_ids_sqrt(self, n_feature):\n",
"        feature_ids = np.arange(n_feature)\n",
"        np.random.shuffle(feature_ids)\n",
"        return feature_ids[range(max(1, int(math.sqrt(n_feature))))]\n",
"\n",
"    def __get_feature_ids_log2(self, n_feature):\n",
"        feature_ids = np.arange(n_feature)\n",
"        np.random.shuffle(feature_ids)\n",
"        return feature_ids[range(max(1, int(math.log2(n_feature))))]\n",
"\n",
"    def __get_feature_ids_N(self, n_feature):\n",
"        return np.arange(max(1, int(n_feature)))\n",
"\n",
"    def __sort_samples(self, x, y):\n",
"        sorted_idx = x.argsort()\n",
"        return x[sorted_idx], y[sorted_idx]\n",
"\n",
"    def __div_samples(self, x, y, feature_id, threshold):\n",
"        left_mask = x[:, feature_id] > threshold\n",
"        right_mask = ~left_mask\n",
"        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
"\n",
"    def __find_threshold(self, x, y):\n",
"        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
"        class_number = self.num_class\n",
"        cut_size = np.int(self.min_samples_split / 2 - 1)\n",
"        if cut_size == 0:\n",
"            split_sorted_y = sorted_y\n",
"        else:\n",
"            split_sorted_y = sorted_y[cut_size:-cut_size]\n",
"        border = np.where(split_sorted_y[:-1] != split_sorted_y[1:])[0] + (cut_size + 1)\n",
"        if len(border) == 0:\n",
"            return np.inf, None\n",
"        ee = border - np.append(np.array([cut_size]), border[:-1])\n",
"        unitary = np.zeros((border.shape[0], class_number))\n",
"        unitary[np.arange(border.shape[0]), sorted_y[border - 1]] = 1\n",
"        class_increments = unitary * ee.reshape(-1, 1)\n",
"        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:cut_size], minlength=class_number)\n",
"        lcc = np.cumsum(class_increments, axis=0)\n",
"        rcc = np.bincount(sorted_y, minlength=class_number) - lcc\n",
"        l_sizes = border.reshape(lcc.shape[0], 1)\n",
"        r_sizes = sorted_y.shape[0] - l_sizes\n",
"        g = self.G_function(lcc, l_sizes, rcc, r_sizes)\n",
"        le = l_sizes[np.argmin(g)][0]\n",
"        return g[np.argmin(g)], (sorted_x[le-1] + sorted_x[le]) / 2.0\n",
"\n",
"    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
"        node = []\n",
"        if((not(depth is None) and depth == self.max_depth) or y.shape[0] <= self.min_samples_split or (Counter(y).most_common(1)[0][1] / y.shape[0]) >= self.sufficient_share):\n",
"            node.append(self.__class__.LEAF_TYPE)\n",
"            if(y.shape[0] > 0):\n",
"                node.append(Counter(y).most_common(1)[0][0])\n",
"            self.tree[node_id] = (node)\n",
"            return self.imperfection(y)\n",
"        node.append(self.__class__.NON_LEAF_TYPE)\n",
"        feature = self.get_feature_ids(x.shape[1])\n",
"        feature_threshold = np.array(list(map(lambda i: list(self.__find_threshold(x[:, i], y)), feature)))\n",
"        best = np.argmin(feature_threshold[:][0])\n",
"        node.append(feature[best])\n",
"        node.append(feature_threshold[best][1])\n",
"        self.tree[node_id] = (node)\n",
"        xl, xr, yl, yr = self.__div_samples(x, y, node[1], node[2])\n",
"        if(yl.shape[0] > 0 and yr.shape[0] > 0):\n",
"            self.feature_importances_[feature[best]] += self.imperfection(y)*(y.shape[0]) - self.__fit_node(xl, yl, 2*node_id+1, depth+1)*(yl.shape[0]) - self.__fit_node(xr, yr, 2*node_id+2, depth+1) * (yr.shape[0])\n",
"        else:\n",
"            node = []\n",
"            node.append(self.__class__.LEAF_TYPE)\n",
"            if(y.shape[0] > 0):\n",
"                node.append(Counter(y).most_common(1)[0][0])\n",
"            self.tree[node_id] = (node)\n",
"        return self.imperfection(y)\n",
"\n",
"    def fit(self, x, y):\n",
"        self.num_class = np.unique(y).size\n",
"        self.feature_importances_ = np.zeros(x.shape[1])\n",
"        self.__fit_node(x, y, 0, 0)\n",
"        fi = self.feature_importances_\n",
"        self.feature_importances_ = fi / np.sum(fi)\n",
"\n",
"    def __predict_class(self, x, node_id):\n",
"        node = self.tree[node_id]\n",
"        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
"            _, feature_id, threshold = node\n",
"            if x[feature_id] > threshold:\n",
"                return self.__predict_class(x, 2 * node_id + 1)\n",
"            else:\n",
"                return self.__predict_class(x, 2 * node_id + 2)\n",
"        else:\n",
"            return node[1]\n",
"\n",
"    def __predict_probs(self, x, node_id):\n",
"        node = self.tree[node_id]\n",
"        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
"            _, feature_id, threshold = node\n",
"            if x[feature_id] > threshold:\n",
"                return self.__predict_probs(x, 2 * node_id + 1)\n",
"            else:\n",
"                return self.__predict_probs(x, 2 * node_id + 2)\n",
"        else:\n",
"            return node[2]\n",
"\n",
"    def predict(self, X):\n",
"        return np.array([self.__predict_class(x, 0) for x in X])\n",
"\n",
"    def predict_probs(self, X):\n",
"        return np.array([self.__predict_probs(x, 0) for x in X])\n",
"\n",
"    def fit_predict(self, x_train, y_train, predicted_x):\n",
"        self.fit(x_train, y_train)\n",
"        return self.predict(predicted_x)\n",
"\n",
"    def score(self, X, y):\n",
"        pred = self.predict(X)\n",
"        sum = 0\n",
"        for i in range(y.shape[0]):\n",
"            sum += pred[i] == y[i]\n",
"        return sum / len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
"    df = pd.read_csv('./data/speed-dating-experiment/Speed Dating Data.csv', encoding='latin1')\n",
"    choseddf = df[['match','gender' ,'age_o', 'race_o','goal','race_o', 'round' ,'condtn',  'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha','dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o',  'prob_o','met_o']].dropna()\n",
"    y = np.array(choseddf['match']).astype('int')\n",
"    X=np.array(choseddf[['gender' ,'age_o', 'race_o','goal','race_o', 'round' ,'condtn',  'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha','dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o',  'prob_o','met_o']]).astype('int')\n",
"    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
"    my_clf = MyDecisionTreeClassifier(min_samples_split=2, criterion='gini', max_features='sqrt')\n",
"    clf = DecisionTreeClassifier(min_samples_split=2,criterion='gini', max_features='sqrt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
"   print(np.argsort(clf.feature_importances_)[-10:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
   "   print(np.argsort(my_clf.feature_importances_)[-10:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
"   param_grid = {'n_estimators': range(1, 10),'max_depth': range(1, 50)}\n",
"   rfc = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
"   Cv = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
"   Cv.fit(X_train, y_train)\n",
"   print(Cv.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
